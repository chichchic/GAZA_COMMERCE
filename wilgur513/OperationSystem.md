# 운영체제
* 컴퓨터의 하드웨어 자원을 관리하는 소프트웨어
* 운영체제 주요 작업
  * 프로세스 관리
  * 메인 메모리 관리
  * 파일 관리
  * 보조기억장치 관리
  * 입출력 장치 관리
  * 시스템 콜

# 커널
* 운영체제의 핵심 부분으로써, 하드웨어 자원을 직접적으로 관리한다.
* 하드웨어와 프로세스의 보안을 책임지고, 하드웨어적인 요소를 추상화하여 하드웨어 종속적인 구조를 막아준다.

# 셸
* 커널과 사용자 사이에 존재하며, 사용자의 요청을 해석해 커널에 전달한다.
* 커널에서 요청이 완료되면 응답을 셀을 통해 사용자에게 전달한다.

# 부팅
* 전원이 켜지면 먼저 ROM에서 POST와 부트 로더를 실행시킨다.
* POST : 현재 컴퓨터의 상태를 확인한다.
* 부트 로더 : 보조기억장치에 있는 운영체제를 RAM에다 적재시킨다. 

# init 프로세스
* 운영체제가 제일 처음 RAM에 적재되면 최초의 프로세스(Unix에서는 init 프로세스)를 생성한다.
* 최초의 프로세스가 다른 프로세스를 생성(fork)한다.

# ROM vs RAM
* ROM
  * 비휘발성 메모리
  * 읽기만 가능
* RAM
  * 휘발성 메모리
  * 읽기, 쓰기가 모두 가능

# 이중 모드
* 이중 모드의 필요성
  * 사용자가 모든 자원에 접근이 가능하면, 주요 자원(메모리)에 접근하여 필수적인 데이터를 망칠 수 있다.
  * 따라서, 이중모드(사용자 모드, 커널모드)를 사용해 일반 사용자는 주요 자원에 직접적으로 접근하지 못하도록 해야한다.
* 커널 모드(= 관리자 모드, 시스템 모드, 특권 모드, 모니터 모드)
  * 하드웨어적인 자원에 접근이 가능합니다.
* 사용자 모드
  * 하드웨어적인 자원에 접근이 불가능합니다.
  * 하드웨어적인 자원 접근을 위해서 System Call을 사용합니다.

# 시스템 콜(System Call)
* 사용자 모드에서 커널 기능을 사용할 수 있게 해준다.
* 시스템 콜 시 사용자 모드에서 커널 모드로 변경된다.
* 시스템 콜 작업이 완료되면 다시 사용자 모드로 돌아간다.

# 프로세스
* 메모리에 적재되어 CPU의 할당을 받은 실행 중인 프로그램
* 코드/데이터/힙/스택 영역으로 나누어 메모리에 적재됨
  * 코드 : 프로그램의 명령어 저장
  * 데이터 : 전역 변수, 정적 변수 저장
  * 힙 : 런타임에 동적으로 할당하여 사용
  * 스택 : 지역 변수, 매개 변수, 함수 호출 정보를 저장
* 각 프로세스는 개별적인 코드/데이터/힙/스택 영역을 가짐
* CPU는 한번에 하나의 프로세스만 실행시킴
* 프로세스 상태
  * New : 메인 메모리에 할당
  * Ready: 할당된 프로그램이 실행을 위한 준비를 마침
  * Running: CPU가 프로세스를 실행
  * Waiting: 프로세스가 I/O로 인해 CPU 할당을 받지 못함, I/O 작업이 끝나면 다시 ready 상태로 돌아가야 함
  * Terminated: 프로세스가 종료

# 프로세스 큐
* CPU는 프로세스 큐를 이용해 다음에 실행시킨 프로세스를 선택합니다.
* 프로세스 큐에는 순서를 할당 받은 프로세스들이 저장됩니다.
* 프로세스 큐에는 프로세스의 정보를 표현하는 PCB가 저장됩니다.
* 프로세스 큐의 종류
  * Job Queue
    * 보조기억장치에 저장된 프로그램 중에서 메모리 적재를 기다리는 프로그램들을 저장
    * Long-term Scheduler가 적재할 프로그램의 순서를 정해준다.
    * Long-term Scheduler는 작업 시간이 가장 오래 걸린다.
  * Ready Queue
    * CPU 할당을 받기위해서 대기하는 프로세스들을 저장
    * Short-term Scheduler가 CPU 할당을 받을 프로세스의 순서를 정해준다.
    * Short-term Scheduler는 작업 시간이 가장 짧다.
  * Device Queue
    * I/O 작업을 위해서 개별 I/O 장치의 할당을 대기하는 프로세스들을 저장
 
# Medium-term Scheduler(Swapper)
  * Swapping을 위해서 Swap in과 Swap out을 할 프로세스를 선택한다.
 
# Swapping
  * 메모리에 적재된 프로세스 중에서 오랫동안 사용하지 않은 프로세스를 하드디스크(Backing Store)로 옮기고(Swap out), 필요시 Backing Store에서 메모리로 다시 적재하는 것(Swap in)을 의미한다.
  * Swapping을 할 때에는 프로세스의 현재 상태를 담은 프로세스 이미지를 사용한다.
  * Swapping을 할 때에는 하드디스크 일부를 분리하여 프로세스 이미지를 저장하는데, Backing Store 또는 Swap Device라고 부른다.
  * Swap out된 프로세스 이미지를 다시 Swap in할 경우 새로운 메모리 공간을 가질 수 있다. 하지만, MMU가 있기 때문에 실행에 문제가 없다.
  * Swapping은 하드디스크에 데이터를 R/W하는 작업이므로 오버헤드가 크다.
  
# 스레드
* 프로세스가 할당받은 자원을 이용하는 실행 단위
* 같은 프로세스 내의 스레드는 코드/힙/데이터는 공유하지만, 개별적인 PC, Stack Point, 스택 영역을 가지고 있음

# 프로세스 vs 스레드
* 프로세스
  * 개별적인 메모리 공간을 사용하므로, 타 프로세스의 영역에 접근할 수가 없다.
  * 타 프로세스의 자원에 접근하기 위해서는 IPC(Inter-Process Communication)를 사용해야한다.
* 스레드
  * 같은 프로세스 내의 힙/데이터/코드 영역을 공유하므로, 프로세스에 비해 효율적으로 통신이 가능하다.
  * 프로세스에 비해 생성 및 종류 시간과 전환시간(문맥 교환)이 짧다.
  * 문맥 교환 시 스택 영역만 변경해주면 된다.

# 멀티 프로세스
* 다수의 프로세서를 활용하여 동시에 프로세스를 실행시키는 상태

# 멀티 스레딩
* 하나의 프로세스에 다수의 스레드를 실행시키는 상태
* 스레드는 프로세스에 비해 문맥 교환 시간이 짧고, 스레드 간 통신 방법이 간단하다.
* 스레드 간 공유하는 자원으로 인해 동기화 문제가 발생할 수 있다.

# 동기화
* 한정적인 공유 자원을 동시에 여러 프로세스/스레드가 접근하면 예기치 못한 문제가 발생할 수 있다.
* 동기화는 프로세스/스레드 간의 공유 자원 접근을 관리하여 문제가 발생하지 않도록 하는 기법이다.
* 동기화 예제
  * 생산자-소비자 문제(Producer-Consumer Problem)
    * 생산자는 소비자를 위한 데이터를 생성, 소비자는 생성된 데이터를 소비
    * 생산자, 소비자 모두가 사용하는 버퍼(임계 영역)를 만들고 동기화하여 문제를 해결
    * 버퍼의 사용 여부를 확인하기 위한 반복문으로 인해 busy-waiting가 발생할 수 있음
    * 추가적인 세마포어(empty[n으로 설정], full[0으로 설정])를 사용해 문제를 해결할 수 있음
  * Reader-Writer Problem
    * 프로세스의 종류를 Reader(데이터를 읽기만 함), Writer(데이터를 씀)로 나누어 동기화 문제를 해결
    * Reader는 동시에 데이터 접근을 허용, Writer가 데이터 접근 시에는 상호배제가 필요
    * Reader-Writer Problem 종류
      * Reader에게 우선순위
        * Reader에게 우선순위를 먼저 줘서 여러 개의 Reader가 데이터를 읽을 수 있다.
        * 대기 중인 Reader가 데이터를 모두 읽은 후에 Writer가 데이터에 접근할 수 있다.
      * Writer에게 우선순위
        * Writer에게 우선순위를 먼저 줘서 Writer가 대기 중일 때 Reader가 대기 하게 되면, 대기 중인 Writer들이 모두 끝난 후에 Reader가 읽게 된다.

# Busy Waiting
* 생산자-소비자 문제에서 버퍼에 데이터가 가득 찼는지, 비었는데 확인하기 위한 반복문이 계속 실행되어 필요없는 CPU 점유를 하는 상태를 뜻함

# 멀티 스레드 vs 멀티 프로세스
* 멀티 스레드
  * 멀티 스레드는 멀티 프로세스보다 스레드를 사용하기 때문에 메모리 공간을 적게 활용하고, 문맥 교환 시간이 짧다.
  * 하지만, 멀티스레드는 동기화 문제가 발생할 수 있다.
* 멀티 프로세스
  * 하나의 프로세스가 문제가 발생해도 다른 프로세스에게 영향을 끼치지 않는다.
  * 멀티 스레드에 비해 프로세스를 활용하기 때문에 메모리 공간과 CPU 시간을 더 차지한다.

# 멀티 프로그래밍
* 단일 프로세서에서 CPU 작업과 I/O 작업을 병행하는 상태
* I/O 작업으로 인해 CPU가 유휴상태가 되면, CPU 작업이 필요한 다른 프로세스를 실행시킴
* CPU의 이용과 처리량을 증가시킬 수 있음

# PCB(Process Control Block)
* 프로세스 생성시 만들어지며, 프로세스 관리에 필요한 정보를 포함하는 커널의 자료구조
* 일반 사용자가 접근하지 못하는 보호된 메모리 영역에 존재함
* 프로세스에 대한 정보
  * 프로세스 식별자(PID)
  * 프로세스 상태
    * 생성(create), 준비(ready), 실행(running), 대기(waiting), 완료(terminated)
  * PC(Program Counter): 프로세스가 다음에 실행할 명령어의 주소
  * CPU 레지스터 및 일반 레지스터
  * CPU 스케줄링 정보: 우선 순위, 최종 실행시각, CPU 점유시간 등
  * 메모리 관리 정보: 해당 프로세스의 주소 공간 등
  * 프로세스 계정 정보: 페이지 테이블, 스케줄링 큐 포인터, 소유자, 부모 등
  * 입출력 상태 정보: 프로세스에 할당된 입출력장치 목록, 열린 파일 목록 등

# 문맥교환(Context Switch)
* 현재 실행중인 프로세스가 인터럽트에 의해 다음 프로세스가 실행되어야 할 때, 기존 프로세스의 상태(문맥)을 PCB에 저장하고 다음 프로세스의 실행을 위해 다음 상태로 교체하는 작업
* 문맥교환이 발생하면 CPU는 아무런 일을하지 못한다. 따라서, 너무 잦은 문맥교환은 CPU의 처리량을 감소시킨다.
* CPU 스케줄러가 다음에 실행할 프로세스를 선택한다.
* 디스패처가 실질적으로 PCB에 프로세스 상태를 저장 및 복원한다.

# 선점 vs 비선점
* 선점
  * 프로세스가 CPU를 점유 중이여도, 다른 프로세스가 강제로 CPU를 점유할 수 있다.
* 비선점
  * CPU에 프로세스가 할당 중이면 점유된 프로세스가 종료되기 전까지 다른 프로세스가 CPU를 점유할 수 없다.

# CPU 스케줄러
* 다음으로 실행할 프로세스를 선택하는 역할을 한다.
* CPU 스케줄러 평가 기준
  * CPU 이용률 : CPU 사용 비율
  * 처리율 : 시간당 처리한 프로세스 수
  * 반환 시간 : 프로세스 첫 작업 시간부터 종료하는데 걸린 시간(CPU, waiting, I/O 등 모든 시간 포함)
  * 대기 시간 : CPU 점유를 위해 대기한 시간(Ready 큐에서 기다린 시간)
  * 응답 시간 : 프로세스 작업 요청 후 응답을 대기하는 시간
* CPU 스케줄링 알고리즘
  * FCFS(First Come Frist Served)
    * 비선점 스케줄링 알고리즘
    * 먼저 도착한 순서대로 프로세스를 CPU에 할당
    * 작업 시간이 긴 프로세스가 먼저 오게 되면 짧은 프로세스들은 오랫동안 기다려야 됨(Convoy Effect)
  * SJF(Shortest Job First)
    * 작업 시간이 짧은 순서대로 CPU에 프로세스를 할당
    * 평균 대기 시간이 짧지만, 작업 시간을 알 수 없으므로 비현실적인 알고리즘
    * 선점, 비선점으로 모두 사용 가능
    * SRTF(Shortest Remain Time First, 비선점)
      * 새로운 프로세스가 도착했을 때, 현재 남은 작업 시간을 기준으로 다시 정렬하여 가장 짧은 작업 시간을 가진 프로세스를 CPU에 할당
  * Priority
    * 우선 순위가 높은 순서대로 CPU에 프로세스를 할당
    * 기아(Starvation)이 발생할 수 있음
    * 에이징(Aging)을 사용해 기아를 해결
    * 선점, 비선점으로 모두 사용 가능
  * Round-Robin
    * 프로세스 별로 돌아가면서 정해진 시간(time quantom) 동안만 CPU를 할당하도록 하는 알고리즘
    * 정해진 시간이 지나면 프로세스는 대기하고, 다음 순서의 프로세스가 실행된다.
    * 프로세스가 종료 되기 전에 time quantum이 끝나면 다음 프로세스로 CPU 할당을 넘겨주기 때문에 선점 스케줄링 알고리즘이다.
    * time quantum이 길면 SJF와 비슷하게 동작하고, 짧으면 문맥 교환이 자주 일어나 비효율적이다.
  * Multilevel Queue
    * 프로세스 그룹(운영체제 커널 수준 프로세스[System Proccess], 유저 수준 프로세스[Interactive Process] 등) 별로 큐를 만들어 사용하는 알고리즘
    * 큐 별로 CPU 할당 시간이나, 알고리즘을 다르게 설정할 수 있다.
  * Multilevel Feedback Queue
    * 여러개의 큐를 활용하고, 각 큐마다 다른 우선순위를 가지고 있다.
    * 큐에는 여러 개의 프로세스가 저장될 수 있고, 같은 큐 내의 프로세스는 같은 우선순위를 가진다.
    * 우선 순위가 높은 큐에 있는 프로세스를 먼저 실행하고, 같은 우선순위를 가진 프로세스가 여러개면 Round Robin 알고리즘을 사용한다.
    * time quantum 안에 프로세스의 작업이 끝나지 않으면 우선순위가 낮은 큐로 이동한다.
    * 대화형 사용자(I/O 작업에서 입력을 기다림)와 같이 반복적으로 time quantum 안에 CPU를 반납할 경우 우선순위를 유지한다.
    * 많은 대화형 사용자가 존재할 경우 우선순위가 낮은(작업 시간이 긴) 프로세스는 실행되지 않는 기아가 발생할 수 있다.
    * 우선순위 상향 조정을 통해서(주기적으로 프로세스의 우선순위를 최상위로 바꾸는 등) 기아를 어느정도 해결할 수 있다.

# 기아(Starvation)
  * 우선순위가 높은 프로세스가 계속해서 Ready 큐에 들어와서 우선순위가 낮은 프로세스가 실행되지 못하고 계속해서 대기되는 상태

# 에이징(Aging)
  * Ready 큐에서 오랫동안 기다리고 있는 프로세스의 우선 순위를 높여줘 우선순위가 낮더라도 실행될 수 있도록 하는 기법
  * 기아를 해결하기 위해서 사용됨

# 인터럽트
* CPU가 프로세스를 실행중일 때, 외부로부터 예외상황이 발생하여 CPU에게 알려주는 것을 의미한다.
* 인터럽트의 종류
  * I/O 요청
  * CPU 사용시간 만료
  * 자식 프로세스를 만들때(fork)
  * 기타 등등

# 커널 스레드 vs 사용자 스레드
* 커널 스레드
  * 커널 모드에서 실행되는 스레드
* 사용자 스레드
  * 사용자 모드에서 실행되는 스레드

# 병렬성
* 여러 개의 프로세스가 동시에 실행됨

# 동시성
* 여러 개의 프로세스가 시분할하여 순차적으로 실행됨
* 사용자는 여러 개의 프로세스가 한번에 실행되는것처럼 느껴짐

# 임계영역(Critical Section)
* 여러 프로세스가 동시에 접근해서는 안되는 자원에 접근하는 영역(즉, 여러개의 프로세스가 공유자원을 사용하는 영역)
* 임계영역에 접근하는 순서에 따라서 결과가 달라짐
* 임계영역을 해결하기 위한 조건
  * 상호배제 : 한 프로세스/스레드가 임계 영역에서 작업 중이면, 타 프로세스/스레드는 접근할 수 없다.
  * 진행 : 임계 영역에서 작업 중인 프로세스/스레드가 없을 때, 동시에 여러 프로세스/스레드가 접근하려하면 어떤 프로세스/스레드를 진행시킬 지 정해야한다.
  * 유한 대기 : 임계 영역 진입을 기다리는 모든 프로세스/스레드는 유한한 시간 안에 진입할 수 있어야 한다.(무한정 대기하면 안된다.)

# 경쟁 상태(Race Condition)
* 여러개의 프로세스가 동일한 임계영역을 가지고, 서로 점유하기 위해 경쟁하는 상태

# 상호배제(Mutual Exclusion)
* 여러개의 프로세스가 임계영역에 동시에 진입하지 않도록 제어하는 매커니즘

# 뮤텍스
* 임계영역에 진입할 수 있는 스레드를 하나로 제한
* 임계영역에 진입하기 위해서는 락을 획득한 다른 스레드가 해제해야지만 진입 가능
* 바이너리 세마포어와 유사한 방식

# 세마포어
* 임계영역에 진입할 수 있는 프로세스를 n개로 제한
* 동기화 대상이 여러개의 프로세스일 때 주로 사용, wait와 signal을 사용해 동기화
  * P(wait)
    * 세마포어 변수를 1감소
    * 세마포어 변수가 0일 때 진입 불가(타 프로세스가 signal을 호출해 자원을 해제해야 진입 가능)
  * V(signal)
    * 세마포어 변수를 1증가
    * 자원을 해제하기 위해서 사용
* 세마포어 변수가 1일 경우(바이너리 세마포어) 뮤텍스처럼 사용 가능 

# 모니터락
* 배타 동기 큐와 조건 동기 큐를 사용해 동기화를 문제를 해결한다.
* 자바에서는 sychronized 키워드와, wait, notify 메서드를 통해 모니터락을 사용할 수 있다.
* 배타 동기 큐
  * 공유 자원에 하나의 프로세스/스레드가 접근할 수 있도록 제어한다. 
  * sychronized 키워드 사용해 배타 동기 큐에 들어갈 수 있다.
* 조건 동기 큐
  * 공유 자원을 점유 중인 프로세스/스레드가 wait()를 호출해 조건 동기 큐에 들어갈 수 있다.
  * 현재 공유 자원을 점유 중인 프로세스/스레드가 notify()를 호출에 조건 동기 큐에 들어간 프로세스/스레드를 깨워줄 수 있다.

# 교착상태(Deadlock)
* 프로세스가 이미 점유된 자원을 요청 시, 해당 자원을 점유한 프로세스가 대기큐에 있어 작업이 끝나길 무한정 기다리는 상태
* 교착 상태가 발생할 수 있는 4가지 조건
  * 상호배제 : 한 프로세스가 자원을 점유 중이면, 타 프로세스가 접근할 수 없다.
  * 환형구조 : 프로세스가 자원을 요구하는 방향이 원형을 이룬다.
  * 비선점 : 한 프로세스가 자원을 점유 중이면, 타 프로세스가 강제로 자원을 점유할 수 없다.
  * 점유와 대기 : 한 프로세스가 다른 자원을 요청하면서, 보유중인 자원을 계속해서 점유한다.
* 교착 상태 해결 방법
  * 무시(ignore)
    * 교착 상태는 4가지 조건을 모두 만족해도 발생하기 어렵기 때문에 무시하는 방법
  * 방지(prevent)
    * 교착 상태 4가지 조건 중 최소 한가지 이상을 만족하지 않도록 하는 방법
    * 방지는 자원을 비효율적으로 사용하는 단점이 있어, 군사, 우주, 의료와 같은 영역에서 사용함
    * 상호 배제 제거
      * 상호 배제를 제거하기 위해서는 모든 자원을 동기화 없이 공유 가능하도록 해야함(현실적으로 불가능)
    * 점유와 대기 제거
      * 필요한 자원 중 일부만 획득한 경우, 모든 자원을 해제하고 다시 대기함
      * 모든 자원을 할당받은 경우에만 실행
      * 기아가 발생할 수 있으며, 자원을 비효율적으로 사용함
    * 비선점 제거
      * 자원을 선점이 가능하도록 하는 것은 현실적으로 불가능
    * 환형 구조 제거
      * 나머지 조건에 비해서 현실적인 방법
      * 자원에 번호를 할당해 오름차순으로 자원을 요청하도록 함
      * 자원을 비효율적으로 사용함
  * 회피(avoid)
    * 안전 할당(Safe Allocation)과 불안정한 할당(Unsafe Allocation) 상태를 구분하여 불안전 할당 상태에서는 교착 상태가 발생함을 알고 회피함
    * Banker's 알고리즘을 사용
  * 감지&복구(dection&recovery)
    * 교착 상태의 발생을 허용함
    * 교착 상태 발생 여부를 주기적으로 확인하여 복구함
    * 감지 주기가 짧으면 오버헤드가 발생하고, 길 경우 복구가 어려워질 수 있음
    * 복구 방법
      * 메모리 상태를 주기적으로 저장하고, 교착상태 감지 시 이전에 저장한 메모리 상태로 복구함
      * 일부 프로세스를 강제 종료하여, 자원을 해제해 교착 상태를 복구함
      * 등등

# 프로그램 빌드 과정
* 소스파일
  * 고수준 언어(C, C++, Java 등) or 어셈블리어
* 목적파일
  * 컴파일 또는 어셈블 결과물(.obj, .class)
* 실행파일
  * 링크의 결과
* 빌드 과정(컴파일 -> 링크 -> 로드)
  * 컴파일 
    * 소스 파일은 컴파일러에 의해 컴파일되고 목적 파일이 생성된다.
    * 컴파일단계에서는 외부 라이브러리에 대한 정보를 추가하지 않는다.
  * 링크
    * 링크 단계는 링커가 수행한다.
    * 외부 라이브러리에 대한 정보를 추가해 실행 파일을 만든다.
  * 로드
    * 로더가 프로그램을 실행하여 메모리에 적재한다.

# 프로그램 메모리 할당 과정
* 프로그램을 적재할 메모리의 주소는 OS가 관리한다.
* 다중 프로그래밍에서는 다양한 프로그램이 적재 및 해제되기 때문에 고정된 메모리 주소를 사용할 수 없다.
* MMU를 이용해 할당할 프로그램의 메모리 주소를 결정한다.

# MMU(Memory Management Unit)
* CPU가 메모리에 접근하는 것을 관리하는 하드웨어 부품
* CPU는 가상 메모리 주소(논리 주소)를 사용하므로 실제 메모리 주소(물리 주소)로 변환해줄 필요가 있음
* MMU는 가상 메모리 주소를 실제 메모리 주소로 변환함
* MMU는 런타임에 논리 주소를 물리 주소로 변환하기 때문에, CPU는 문제없이 논리 주소를 사용할 수 있다.
* MMU 구성 요소
  * Relocation Register
    * 프로세스들의 실제 시작 메모리 주소 정보를 가지고 있어, 프로세스의 시작 주소를 제공해준다.
  * Base&Limit Register
    * CPU에서 사용하는 주소가 Base와 Limit 볌위를 벗어나는 메모리 주소를 접근할 경우 인터럽트가 발생한다.

# 메모리 적재
* 동적 적재
  * 프로그램 실행에 필요한 필수적인 부분(필요한 루틴이나 데이터)만 우선 적재하고, 필요 시 필요한 부분을 메모리에 적재하는 방법이다.
* 정적 적재
  * 프로그램의 모든 부분을 실행 시 메모리에 적재하는 방법

# 동적 연결(Dynamic Linking)
* 동일한 라이브러리를 사용하는 여러개의 프로그램은 일반적으로 메모리에 중복되서 라이브러리가 적재된다.
* 공통으로 사용되는 라이브러리를 메모리에 하나만 올려 공유하는 방법이 동적 연결이다.
* 동적 연결은 링크 과정이 프로그램이 메모리에 적재된 이후에 수행한다.
* Linux에서는 공유 라이브러리(Shared Library), Windows에서는 동적 연결 라이브러리(Dynamic Linking Library, DLL)이라고 부른다.

# 정적 연결(Static Linking)
* 공유할 수 있는 라이브러리를 프로그램 별로 메모리에 중복해서 적재하는 방법
* 같은 라이브러리가 메모리에 중복되어 있기 때문에 메모리 낭비가 생긴다.
* 실행 파일이 생성되기 전에 링크 단계에서 필요한 라이브러리를 모두 연결한다.

# 단편화
* 프로세스가 자주 할당/해제되면서 여러개의 크기가 다양한 hole(메모리 공간 중 비어있는 공간, free)생긴다.
* hole들이 불연속적으로 생성되어 있는 상태를 단편화라고 한다.

# 외부 단편화
* 적재하려는 프로세스의 메모리 크기가 남아 있는 hole들보다 커서 적재할 수 없는 상태

# 메모리 할당 기법
* 최초 적합(First Fit)
  * hole들 중에서 적재가 가능한 첫번째 hole에 적재
  * 3가지 방법 중 가장 빠른 속도를 가짐
  * 최적 적합과 비슷한 메모리 이용률을 가짐
* 최적 적합(Best Fit)
  * hole들 중에서 프로세스 크기와 차이가 가장 적은 hole에 적재
  * 외부 단편화로 인해 전체 메모리의 1/3정도 낭비함...
* 최악 적합(Worst Fit)
  * hole들 중에서 프로세스 크기와 차이가 가장 큰 hole에 적재
* 압축(Compaction)
  * 흩어져있는 hole들을 하나로 합치는 방법
  * hole들을 옮기는 오버헤드가 큰 단점이 있음

# 페이징
* 프로세스를 일정한 크기의 페이지로 나누어 메모리에 적재하는 방법
* 메모리 상에 같은 프로세스가 흩어져서 존재할 수 있는데, 페이지 테이블을 이용해 CPU가 연속적인 메모리 공간이라고 생각하게 만듬
* 페이지 보호 및 공유
  * 페이지 별로 비트를 두어 읽기(r), 쓰기(w), 실행(x) 작업을 제한할 수 있다.
  * 같은 프로세스는 같은 code 영역을 가진다. code 영역을 프로세스끼리 공유하여 메모리를 효율적으로 사용할 수 있다.
  * 단, code는 변하지 않는 프로그램이어야 한다.
* 페이지 크기에 따른 성능
  * 내부 단편화
    * 크기가 작을 수록 내부 단편화가 줄어든다.
  * 페이지 부재 확률
    * 페이지가 클 수록 필요한 페이지가 프레임에 할당될 확률이 높아 페이지 부재가 줄어 든다. 
  * 페이지 테이블의 크기
    * 페이지가 클 수록 페이지 개수가 줄어들어 페이지 테이블의 크기도 줄어든다.
  * 메모리 해상도(Memory Resolution)
    * 페이지가 작을 수록 불필요한 데이터가 줄기 때문에 메모리 해상도는 증가한다.
  
# 메모리 해상도(Memory Resolution)
* 해당 메모리에 필요한 데이터가 있을 확률이다.

# 페이지 vs 프레임
* 페이지
  * 프로세스를 일정한 크기로 나눈 조각
* 프레임
  * 실제 메모리를 일정한 크기로 나눈 조각
  * 페이지와 크기가 동일하다.

# 페이지 테이블
* CPU가 사용하는 논리 주소를 이용해 실질적인 물리 주소로 변환해준다.
* 물리적인 메모리 상에서 흩어져 있는 페이지를 CPU가 느끼기에는 연속적인 메모리 공간에 적재되어 있는 것처럼 만들어줌
* 주소 변환
  * 논리 주소
    * CPU가 사용함
    * 페이지 번호(p)와 변위(d)로 구성된다.
    * 총 m비트로 구성되어 있을 때, 하위 n비트는 오프셋(offset) 또는 변위라고 한다.
    * 상위 m-n비트는 페이지 번호를 나타낸다.
  * 물리 주소
    * 논리 주소의 페이지 번호(p)와 변위(d)를 사용해 구한다.
    * 페이지 테이블에서 페이지번호와 매칭되는 프레임 번호(f)를 찾고 뒤에 변위(d)를 붙여서 물리 주소를 계산한다.

# 내부 단편화
* 프로세스의 크기가 페이지 크기의 배수가 아닐 때, 마지막 페이지에서 남는 공간을 의미한다.
* 일반적으로 외부 단편화에 비해 낭비되는 메모리 공간이 작으며, 페이지 크기에 좌우 된다.(내부 단편화 크기 : 0 ~ 페이지 크기 - 1)

# 페이지 테이블 생성
* CPU 내의 레지스터 사용
  * 주소 변환 속도가 빠르지만, 공간이 한정적이여서 페이지 테이블의 크기가 작다.
* 메모리 사용
  * CPU 레지스터를 쓸 때보다 느리지만, 공간이 많아 페이크 테이블의 크기를 크게 만들 수 있다.
  * 메모리를 사용하면 주소를 변환하기 위해서 메모리에 2번 접근해야한다.(페이지 테이블 접근, 프레임 접근)
* TLB(Translation Look-aside Buffer) 사용
  * TLB는 페이지 테이블을 위한 캐시이다. CPU와 메모리 사이에 존재한다.
  * 주소 변환 속도는 메모리 사용보다는 빠르고, 메모리 크기는 CPU 레지스터 보다 크다.
  * 실제 페이지는 메모리에 있고, TLB는 캐시 용도로 일부 페이지만 TLB에 저장한다.
  * TLB에 유효한 페이지가 있으면 TLB를 읽는 시간과 메모리를 읽는 시간만 필요하다.
  * TLB에 유효한 페이지가 없으면, TLB에 페이지를 쓰고 읽어야하므로 메모리를 2번 읽어야한다.

# 세그멘테이션
* 프로세스를 일정하지 않는 크기의 세그먼트를 이용해 나눠서 메모리에 적재하는 방법
* 세그먼트 테이블을 사용해 논리적인 주소를 물리적인 주소로 변환한다.
* 세그먼트 테이블 보호 & 공유
  * 세그먼트를 논리적으로 나누기 때문에(같은 성향의 데이터만 세그먼트로 묶기 때문에) R/W/X의 작업 제한을 하기 좋다.
  * 세그먼테이션은 code 영역만 세그먼트로 나눌 수 있기 때문에 공유에서도 효율적이다.
* 세그멘테이션 단점
  * 세그먼트의 크기가 다양하기 때문에 다양한 크기의 hole이 생성되고 외부 단편화가 생긴다.
* 세그멘테이션 보완
  * 세그멘테이션의 단점을 보완하기 위해서 세그먼트를 페이징 기법으로 사용할 수 있다.(외부 단편화 문제 해결)
  * 하지만, 메모리 주소 변환을 두번 해야한다.(논리 주소 -> 세그먼트 테이블 -> 페이지 테이블 -> 물리 주소)

# 세그먼트
* 세그먼트는 페이지와 달리 크기가 일정하지 않는 조각
* code/stack/heap/data 별로 나눈 조각을 세그먼트라고 할 수 있고, 그 안에서 더 세부적으로 세그먼트를 쪼갤 수도 있다.

# 세그먼트 테이블
* 세그먼트 페이지 번호와 변위를 이용해 실질적인 물리주소로 변환한다.
* 세그먼트 테이블에는 세그먼트 페이지의 시작 주소(base)와 세그먼트 크기(limit)를 저장한다.

# 가상 메모리
* 주기억장치의 공간 부족으로 보조기억장치를 이용해 메모리 공간을 가상으로 늘려주는 기법 
* 물리 메모리보다 큰 프로세스를 실행시키기 위해서 사용한다.

# 요구 페이징(Demanding Paging)
* 프로세스에서 현재 실행에 필요한 부분만(페이지 or 세그먼트) 적재시켜 프로세스를 실행시킨다.
* valid bit를 사용해 페이지 테이블에 페이지가 존재하는지 확인할 수 있다.
* valid bit가 0이면 페이지 존재하지 않으므로, CPU에 인터럽트 신호를 보내 메모리에 원하는 페이지를 적재시킨다.
* 요구 페이징 종류
  * Pure Demanding Paging
    * 프로세스가 최초로 실행될 때 어떤 페이지가 필요한지 모르기 때문에, 아무 페이지도 올리지 않는다.
    * 따라서, 프로세스 시작 부분에 페이지 부재가 발생하고 페이지를 탐색하여 프레임에 할당한다.
    * 메모리를 효율적으로 사용할 수 있지만, 시작부터 페이지 부재가 발생해 속도가 느리다.
  * Preparing
    * 프로세스가 최초로 실행될 때 필요한 것으로 보이는 페이지를 먼저 프레임에 할당한다.
    * 페이지 부재가 발생하지 않아 속도는 빠르지만, 프레임에 할당된 페이지를 사용하지 않으면 메모리를 낭비할 수 있다.
* 유효 접근 시간
  * p : 페이지 부재 확률
  * Tm : 메모리를 읽는 시간
  * Tp : 페이지 부재 발생 시 소요시간
  * T(유효 접근 시간) = (1 - p) * Tm + p * Tp 
  * 페이지 부재 확률이 낮을 수록 유효 접근 시간이 짥고 효율적이다.

# 페이지 부재(Page Fault)
* CPU가 접근하려는 페이지가 메모리에 없는 상태이다.(페이지 테이블에서 valid bit가 0인 경우)
* 페이지 부재 처리 과정
  * 페이지가 메모리에 적재되어 있는지 확인(valid bit 사용)
  * valid bit가 0 이면, CPU에 인터럽트를 발생시켜 ISR로 점프
  * ISR에서 Backing Store를 탐색하여 페이지를 찾는 작업 수행
  * 탐색한 페이지를 프레임에 할당(valid bit를 1로 설정)
  * 인터럽트 발생 이전의 명령어 수행

# 지역성의 원리
* 메모리 접근에는 시간적, 공간적인 지역성을 가지고 있다.
* 따라서, 페이지 부재가 일어날 확률이 매우 낮다.
* 시간적 지역성 
  * CPU는 시간이 지나도 동일한 메모리 공간을 접근할 확률이 높다.
  * 예시) 반복문은 동일한 코드 공간을 여러번 접근한다.
* 공간적 지역성
  * CPU가 메모리를 읽을 때, 근처에 있는 메모리 공간에 접근할 확률이 높다.
  * 예시) 절차적인 코드는 순서대로 처리되므로, 근처에 있는 메모리 공간에 접근한다.

# 페이지 교체
* 메모리의 프레임이 모두 할당되어 있다면, 새로운 페이지를 할당하기 위해 기존의 페이지를 Backing Store로 보내고(page out), 새로운 페이지를 메모리에 할당한다.(page in)
* 페이지 참조열
  * 페이지 교체 알고리즘을 위해서는 이진수의 주소가 아닌 페이지 번호가 필요하다.
  * 연속적으로 같은 페이지를 사용할 때에는 하나의 페이지만 남겨도 된다.(연속된 부분에서 페이지부재는 한번만 발생하기 때문)
* 페이지 교체 알고리즘
  * FIFO(First In First Out)
    * 가장 먼저 들어온 페이지(가장 오래된 페이지)를 교체한다.
    * 처음부터 활발히 사용하던 페이지를 교체하여 페이지 부재를 높일 수도 있다.
    * Belady의 모순(Belady's Anomaly)이 발생한다.
  * Optional(OPT)
    * 가장 오랫동안 사용하지 않을 페이지를 교체한다.
    * 낮은 페이지 부재율을 보이며, Belady의 모순이 발생하지 않는다.
    * 미래에 필요한 페이지를 예상하는 것은 현실적으로 불가
  * Least-Recently-Used(LRU)
    * 가장 오랫동안 사용하지 않은 페이지를 교체한다.
    * FIFO보다는 부재율이 낮고, OPT보다는 부재율이 높다.
  * 
      
# Belady의 모순(Belady's Anomaly)
* 프레임 수가 늘어나면 페이지 부재가 일어날 확률이 줄어야하지만 반대로 페이지 부재 확률이 더 많이 발생하는 현상

# 희생양 페이지(Victim Page)
* 페이지 교체가 일어날 때, Backing Store로 보내지는 페이지를 희생양 페이지(Victim Page)라고 한다.
* 희생양 페이지는 CPU에 의해 수정되지 않은 페이지를 선택하는 것이 좋다. Backing Store에 변경된 페이지를 쓰지 않아도 되기 때문이다.
* 페이지 테이블에 modified bit(=dirty bit)와 같은 비트를 두어 수정되지 않은 페이지를 찾을 수 있다.

# Swapping vs Demading Paging
* 둘 다 Backing Store를 사용해 메모리를 관리한다.
* Swapping은 프로세스 단위로 사용하고, Demading Paging은 페이지 단위로 사용한다.

# Global Replacement vs Local Replacement
* Global Replacement
  * 메모리 상의 모든 프로세스 페이지에 대해서 페이지 교체가 일어난다.
  * Local Replacement보다 메모리 사용 효율이 좋다.
* Local Replacement
  * 메모리 상의 자신의 프로세스 페이지에 대해서 페이지 교체가 일어난다.

# 쓰레싱(Thrashing)
* 일정한 범위 내에서는 메모리에 올라가는 프로세스의 개수가 많을 수록 CPU의 이용률이 증가한다.
* 쓰레싱은 메모리에 올라가는 프로세스의 개수가 일정 범위를 넘어가면, CPU의 이용률이 감소하는 현상이다.
* 원인
  * 프로세스가 많을수록 비어있는 프레임이 줄고, 결국 모든 프레임이 가득 찰 수가 있다.
  * 프레임이 가득차게 되면 페이지 교체가 일어나게 되고, 프로세스의 개수가 많을 수록 자주 일어나게 된다.
  * 페이지 교체에서 Page in/out은 I/O 작업으로 CPU를 사용하지 않는다.
  * 따라서, 과도한 페이지 교체로 인해 I/O 작업이 증가하고, CPU 이용률이 줄게 된다.
* 해결 방법
  * Global Replacement보다 LocalReplacement를 사용
    * 메모리 사용 효율이 줄어드는 단점이 있다.
  * 프로세스당 적절한 수의 프레임을 할당
    * 정적 할당
      * 동일 할당
        * 모든 프로세스에게 동일한 양의 프레임을 할당
        * 프로세스 크기에 따라 비효율적임
      * 비례 할당
        * 프로세스의 크기에 비례하여 프레임을 할당
        * 프로세스의 크기가 커 많은 프레임을 할당 받았지만, 모든 프레임을 사용하지 않아 비효율적일 수 있다.
    * 동적 할당
      * Working Set Model
        * 프로세스가 필요로 하는 페이지는 지역성(시간적, 공간적)을 가지고 있다.
        * 프로세스가 미래에 필요로 하는 페이지는 예측하기 어려우므로, 과거의 기록으로 필요한 프레임의 개수를 파악한다.
        * Working Set의 개수만큼 프레임을 할당한다.

# Working Set
* 프레임을 동적으로 할당하는 Working Set Model에서 사용한다.
* 일정 시간 이전부터 현재까지 사용되었던 페이지 집합을 의미한다.

# PFF(Page-Fault Frequency)
* 페이지 부재 비율은 프레임 수에 반비례한다. 즉, 프레임의 수가 작을 수록 페이지 부재 비율은 증가한다.
* 프레임 수에 따른 페이지 부재 비율을 표현하는 그래프에서 상한선과 하한선을 설정해, 상한선보다 부재가 심하면 프레임을 더 할당하고, 하한선보다 부재가 덜 발생하면 할당된 프레임수를 줄인다.





